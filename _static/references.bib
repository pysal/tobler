@article{Cromley2012a,
  abstract        = {Areal interpolation has been developed to provide attribute estimates whenever data compilation or an analysis requires a change in the measurement support. Over time numerous approaches have been proposed to solve the problem of areal interpolation. Quantile regression is used in this study as the basis of the areal interpolator because it provides estimates conditioned on local parameters rather than global ones. An empirical case study is provided using a data set in northern New England. Land cover data, provided by the National Oceanic Atmospheric Administration, derived from remotely sensed images for 2001 captured by the LANDSAT Thematic Mapper at a resolution of 30 ? 30 meters, are used for the ancillary variables for the regression model. The utility of quantile regression as an areal interpolation method is evaluated against simple averages, areal weighting, dasymetric interpolation, and ordinary least squares and spatial regression methods. For the empirical data set used in the study, results show that quantile regression was a better interpolator for the given data set but that binary dasymetric interpolation was a close second. These results were only for one data set and further evaluation is necessary before more general conclusions can be made. Areal interpolation has been developed to provide attribute estimates whenever data compilation or an analysis requires a change in the measurement support. Over time numerous approaches have been proposed to solve the problem of areal interpolation. Quantile regression is used in this study as the basis of the areal interpolator because it provides estimates conditioned on local parameters rather than global ones. An empirical case study is provided using a data set in northern New England. Land cover data, provided by the National Oceanic Atmospheric Administration, derived from remotely sensed images for 2001 captured by the LANDSAT Thematic Mapper at a resolution of 30 ? 30 meters, are used for the ancillary variables for the regression model. The utility of quantile regression as an areal interpolation method is evaluated against simple averages, areal weighting, dasymetric interpolation, and ordinary least squares and spatial regression methods. For the empirical data set used in the study, results show that quantile regression was a better interpolator for the given data set but that binary dasymetric interpolation was a close second. These results were only for one data set and further evaluation is necessary before more general conclusions can be made.},
  author          = {Cromley, Robert G. and Hanink, Dean M. and Bentley, George C.},
  doi             = {10.1080/00045608.2011.627054},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Cromley, Hanink, Bentley - 2012 - A Quantile Regression Approach to Areal Interpolation.pdf:pdf},
  isbn            = {0004-5608},
  issn            = {00045608},
  journal         = {Annals of the Association of American Geographers},
  keywords        = {areal interpolation,dasymetric mapping,linear programming,quantile regression},
  mendeley-groups = {boundary-harmonization},
  number          = {4},
  pages           = {763--777},
  title           = {{A Quantile Regression Approach to Areal Interpolation}},
  volume          = {102},
  year            = {2012}
}
@article{Eicher2001,
  abstract        = {Dasymetric maps display statistical data in meaningful spatial zones. Such maps can be preferable to choropleth maps that show data by enumeration zones, because dasymetric zones more accurately represent underlying data distributions. Though dasymetric mapping has existed for well over a century, the methods for producing these maps have not been thoroughly examined. In contrast, research on areal interpolation has been more thorough and has examined methods of transferring data from one set of map zones to another, an issue that is applicable to dasymetric mapping. Inspired by this work, we tested five dasymetric mapping methods, including methods derived from work on areal interpolation. Dasymetric maps of six socio-economic variables were produced fm a study area of 159 counties in the eastern U.S. using county choropleth data and ancillary land-use data. Both polygonal (vector) and grid (raster) dasymetric methods were tested. We evaluated map accuracy using both statistical analyses and visual presentations of error. A repeated-measures analysis of variance showed that the traditional limiting variable method had significantly lower error than the other four methods. In addition, polygon methods had lower error than their grid-based counterparts, though the difference was not statistically significant. Error maps largely supported the conclusions from the statistical analysis, while also presenting patterns of error that were not obvious from the statistics.},
  author          = {Eicher, Cory L. and Brewer, Cynthia A.},
  doi             = {10.1559/152304001782173727},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Eicher, Brewer - 2001 - Dasymetric Mapping and Areal Interpolation Implementation and Evaluation.pdf:pdf},
  isbn            = {1523040017},
  issn            = {1523-0406},
  journal         = {Cartography and Geographic Information Science},
  keywords        = {areal interpolation,dasymetric mapping},
  mendeley-groups = {boundary-harmonization},
  number          = {2},
  pages           = {125--138},
  title           = {{Dasymetric Mapping and Areal Interpolation: Implementation and Evaluation}},
  url             = {http://www.tandfonline.com/doi/abs/10.1559/152304001782173727},
  volume          = {28},
  year            = {2001}
}
@misc{Fisher1996,
  abstract        = {Areal interpolation is the process by which data collected from one set of zonal units can be estimated for another zonal division of the same space that shares few or no boundaries with the first. In previous research, we outlined the use of dasymetric mapping for areal interpolation and showed it to be the most accurate method tested. There we used control information derived from classified satellite imagery to parameterize the dasymetric method, but because such data are rife with errors, here we extend the work to examine the sensitivity of the population estimates to error in the classified imagery. Results show the population estimates by dasymetric mapping to be largely insensitive to the errors of classification in the Landsat image when compared with the other methods tested. The dasymetric method deteriorates to the accuracy of the next worst estimate only when 40{\%} error occurs in the classified image, a level of error that may easily be bettered within most remote sensing projects.},
  author          = {Fisher, Peter F. and Langford, Mitchel},
  booktitle       = {Professional Geographer},
  doi             = {10.1111/j.0033-0124.1996.00299.x},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Fisher, Langford - 1996 - Modeling sensitivity to accuracy in classified imagery A study of areal interpolation by dasymetric mapping.pdf:pdf},
  isbn            = {0033-0124},
  issn            = {14679272},
  keywords        = {Accuracy,Areal interpolation,Dasymetric mapping,Error,Sensitivity analysis},
  mendeley-groups = {boundary-harmonization},
  number          = {3},
  pages           = {299--309},
  title           = {{Modeling sensitivity to accuracy in classified imagery: A study of areal interpolation by dasymetric mapping}},
  volume          = {48},
  year            = {1996}
}
@article{Flowerdew1991,
  abstract        = {This paper reports on a research project concerned with the areal interpolation problemâ€”the problem of comparing different data sets when they have been made available for different zonal systems. Our approach is based on using additional information to guide the interpolation process. This paper emphasizes recent work applying the method to Poisson and binomially distributed data. There is also discussion of how the method can best be implemented in a geographic information system.},
  author          = {Flowerdew, Robin and Green, Mick and Kehris, Evangelos},
  doi             = {10.1007/BF01434424},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Flowerdew, Green, Kehris - 1991 - Using areal interpolation methods in geographic information systems.pdf:pdf},
  isbn            = {1056-8190},
  issn            = {10568190},
  journal         = {Papers in Regional Science},
  mendeley-groups = {boundary-harmonization},
  number          = {3},
  pages           = {303--315},
  title           = {{Using areal interpolation methods in geographic information systems}},
  volume          = {70},
  year            = {1991}
}
@article{Goodchild_1993,
  author          = {Goodchild, Michael F. and Anselin, Luc and Deichmann, U.},
  doi             = {10.1068/a250383},
  issn            = {0308-518X},
  journal         = {Environment and Planning A},
  mendeley-groups = {segregation,boundary-harmonization},
  month           = {mar},
  number          = {3},
  pages           = {383--397},
  publisher       = {SAGE Publications},
  title           = {{A Framework for the Areal Interpolation of Socioeconomic Data}},
  url             = {http://dx.doi.org/10.1068/a250383 http://journals.sagepub.com/doi/10.1068/a250383},
  volume          = {25},
  year            = {1993}
}
@phdthesis{Hawley2005,
  author          = {Hawley, Kevin},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Hawley - 2005 - A Comparative Analysis of Areal Interpolation Methods.pdf:pdf},
  mendeley-groups = {boundary-harmonization},
  school          = {The Ohio State University},
  title           = {{A Comparative Analysis of Areal Interpolation Methods}},
  year            = {2005}
}
@article{Jia2016,
  abstract        = {Spatial techniques and fine-scale geographic data may be combined in a variety of innovative ways to serve high-resolution population modeling efforts at local scales, which has been further facilitated by growing computation power and access to open-source spatial data. Previous work has highlighted the importance of a dasymetric approach to produce a parcel-based high-resolution gridded population surface (HGPS). In this study, we investigate the application of land-cover data integrated with the parcel-based HGPS to further improve the accuracy of the HGPS. Consideration is given to twelve combinations made by three land cover strategies (1- no land cover class, 2- five separate classes, and 3- three combined classes) and four property type strategies (1- seven types from an empirical study, 2- eight residential types, 3- seventeen types within Alachua County, and 4- twenty-five types within Florida). Results from different strategies are statistically compared with the most significant combination identified as three combined land-cover classes (heavy vegetation, 0-50{\%} and {\textgreater}50-100{\%} impervious surface) and with seven property types from the empirical study (single family, mobile family, multi-family (â‰¥10 and {\textless}10 units), condominiums, mobile homes parks, and homes for the aged). A final data set named the Enhanced HGPS (E-HGPS) is created for Alachua County, Florida, with a distribution of population counts at the scale of individual housing units. This study highlights an innovative approach to incorporating land-cover and parcel data for the purpose of spatial population modeling, and holds potential to broaden the E-HGPS to a state or regional scope.},
  author          = {Jia, Peng and Gaughan, Andrea E.},
  doi             = {10.1016/j.apgeog.2015.11.006},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Jia, Gaughan - 2016 - Dasymetric modeling A hybrid approach using land cover and tax parcel data for mapping population in Alachua Count.pdf:pdf},
  issn            = {01436228},
  journal         = {Applied Geography},
  keywords        = {Dasymetric mapping,Disaggregation,GIS,Land cover,Parcel,Population},
  mendeley-groups = {boundary-harmonization},
  pages           = {100--108},
  publisher       = {Elsevier Ltd},
  title           = {{Dasymetric modeling: A hybrid approach using land cover and tax parcel data for mapping population in Alachua County, Florida}},
  url             = {http://dx.doi.org/10.1016/j.apgeog.2015.11.006},
  volume          = {66},
  year            = {2016}
}
@article{Kim2010,
  abstract        = {Dasymetric-mapping and pycnophylactic-interpolation methods have solid theoretical foundations and empirical supports in population-estimation research. Each of the methods has its own strengths, but also suffers obvious shortcomings. Dasymetric mapping makes good use of ancillary information to infer most likely population distribution, whereas it suffers from the unfounded assumption of uniform distribution of population among all eligible locations. Pycnophylactic interpolation warrants a smooth population surface in the study area without any presumption of uniform distribution. However, the method does not draw on information about real population distribution, so that its estimation accuracy cannot benefit from such useful information. In this paper, we develop a hybrid approach that takes advantage of the strengths and remedies the flaws of both methods. The hybrid method is tested with a case study. To evaluate the performance of the proposed hybrid method, this study compares its estimation accuracy with those of other popular methods including areal-weighting interpolation, binary dasymetric mapping and the pycnophylactic-interpolation method. The comparison results prove that the proposed hybrid method significantly outperforms the other methods. In addition, the study conducts a sensitivity analysis to examine the effect of search-radius size, which is the key parameter of the hybrid method, on estimation accuracy. The analysis result shows that the hybrid method can be further improved with appropriate choice of search radius.},
  author          = {Kim, Hwahwan and Yao, Xiaobai},
  doi             = {10.1080/01431161.2010.496805},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Kim, Yao - 2010 - Pycnophylactic interpolation revisited integration with the dasymetric-mapping method.pdf:pdf},
  issn            = {0143-1161},
  journal         = {International Journal of Remote Sensing},
  mendeley-groups = {boundary-harmonization},
  month           = {nov},
  number          = {21},
  pages           = {5657--5671},
  title           = {{Pycnophylactic interpolation revisited: integration with the dasymetric-mapping method}},
  url             = {https://www.tandfonline.com/doi/full/10.1080/01431161.2010.496805},
  volume          = {31},
  year            = {2010}
}
@article{Langford2006,
  abstract        = {Interpolating population data between incompatible spatial zones is an important task in many GIS applications. This paper investigates whether regional regression models between population and land cover outperform a global approach, and whether the 3-class dasymetric method improves upon the binary dasymetric approach. In the experiments conducted, regional regressions resulted in better areal interpolation, but also highlighted spatial non-stationarity in the relationship between population and land cover. The benefits of a 3-class dasymetric model over a binary model were inconclusive. However, it is suggested that greater flexibility in model calibration to more fully incorporate spatial non-stationarity could improve 3-class dasymetric performance. Accurate urban residential density mapping is also important since the 3-class dasymetric method seems less robust than the binary approach to land cover classification error. {\textcopyright} 2004 Elsevier Ltd. All rights reserved.},
  author          = {Langford, Mitchel},
  doi             = {10.1016/j.compenvurbsys.2004.07.001},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Langford - 2006 - Obtaining population estimates in non-census reporting zones An evaluation of the 3-class dasymetric method.pdf:pdf},
  isbn            = {0198-9715},
  issn            = {01989715},
  journal         = {Computers, Environment and Urban Systems},
  keywords        = {Dasymetric,Interpolation,Population,Regression},
  mendeley-groups = {boundary-harmonization},
  number          = {2},
  pages           = {161--180},
  title           = {{Obtaining population estimates in non-census reporting zones: An evaluation of the 3-class dasymetric method}},
  volume          = {30},
  year            = {2006}
}
@article{Langford2007,
  abstract        = {Areal interpolation between one partitioning of geographical space and another remains an important topic, particular in terms of population counts and related statistics which are often required in order to compute an incidence ratio. Despite numerous recent developments in intelligent areal interpolation methods, and studies that have demonstrated their clear advantage over simple areal weighting, there is little evidence to suggest widespread usage amongst the GIS user community. It is argued that to encourage greater uptake such methods must offer simplicity and convenience. Areal interpolation based on binary dasymetric mapping is conceptually simple, but examples to date tend to use information extracted from multi-spectral satellite imagery which limits its perceived convenience. This paper examines a simple method to extract equivalent information from a raster pixel map. It is shown to offer comparable areal interpolation performance at considerably less cost in terms of both time and complexity. {\textcopyright} 2006 Elsevier Ltd. All rights reserved.},
  author          = {Langford, Mitchel},
  doi             = {10.1016/j.compenvurbsys.2005.07.005},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Langford - 2007 - Rapid facilitation of dasymetric-based population interpolation by means of raster pixel maps.pdf:pdf},
  isbn            = {0198-9715},
  issn            = {01989715},
  journal         = {Computers, Environment and Urban Systems},
  keywords        = {Dasymetric,Interpolation,Population,Raster},
  mendeley-groups = {boundary-harmonization},
  number          = {1},
  pages           = {19--32},
  title           = {{Rapid facilitation of dasymetric-based population interpolation by means of raster pixel maps}},
  volume          = {31},
  year            = {2007}
}
@article{Leyk_2013,
  author          = {Leyk, Stefan and Nagle, Nicholas N and Buttenfield, Barbara P},
  doi             = {10.1111/gean.12011},
  file            = {:Users/knaaptime/Dropbox/Academic/literature/gean.12011.pdf:pdf},
  issn            = {00167363},
  journal         = {Geographical Analysis},
  mendeley-groups = {boundary-harmonization},
  month           = {jul},
  number          = {3},
  pages           = {285--306},
  publisher       = {Wiley-Blackwell},
  title           = {{Maximum Entropy Dasymetric Modeling for Demographic Small Area Estimation}},
  url             = {http://dx.doi.org/10.1111/gean.12011 http://doi.wiley.com/10.1111/gean.12011},
  volume          = {45},
  year            = {2013}
}
@article{Lin2011,
  abstract        = {Areal interpolation is used to transfer attribute information from the initial set of source units with known values to the target units with unknown values before subsequent spatial analysis can occur. The areal units with unknown attribute information can be either at a finer scale or misaligned with respect to the source data layer. This article presents and describes a geographically weighted regression (GWR) method for solving areal interpolation problems for nested areal units and misaligned areal units. Population data, selected as the attribute information, are interpolated from census tracts to block groups (a finer scale) and pseudo-tracts (misaligned from tracts but at the same approximate scale). Root mean square error, adjusted root mean square error, and mean absolute error are calculated to evaluate the performance of the interpolation methods. The land cover data derived from Landsat Thematic Mapper Satellite Imagery with a 30?30 m spatial resolution are applied to as the ancillary data to describe the underlying distribution of population. To evaluate the utility of GWR as an areal interpolation method, the simple areal weighting method, a dasymetric method, and different ordinary least squares regression methods are used in this article as comparison methods. Results suggest that GWR is a better interpolator for the misaligned data problem than for the finer scale data problem. The latter is a result of issues associated with the scaling step to ensure the pycnophylatic property required in areal interpolation.},
  author          = {Lin, Jie and Cromley, Robert and Zhang, Chuanrong},
  doi             = {10.1080/19475683.2010.540258},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Lin, Cromley, Zhang - 2011 - Using geographically weighted regression to solve the areal interpolation problem.pdf:pdf},
  isbn            = {1947-5683},
  issn            = {19475683},
  journal         = {Annals of GIS},
  keywords        = {Areal interpolation,Geographically weighted regression,Spatial interpolation},
  mendeley-groups = {boundary-harmonization},
  number          = {1},
  pages           = {1--14},
  title           = {{Using geographically weighted regression to solve the areal interpolation problem}},
  volume          = {17},
  year            = {2011}
}
@article{Lin2015,
  abstract        = {Control data are critical for improving areal interpolation results. Remotely sensed imagery, road network, and parcels are the three most commonly used ancillary data for areal interpolation of population. Meanwhile, the open access geographic data generated by social networks is emerging as an alternative control data that can be related to the distribution of population. This study evaluates the effectiveness of geo-located night-time tweets data as ancillary information and its combination with the three commonly used ancillary datasets in intelligent areal interpolation. Due to the skewed Twitter user age, the other purpose of this study is to test the effect of age bias control data on estimation of different age group populations. Results suggest that geo-located tweets as single control data does not perform as well as the three other control layers for total population and all age-specific population groups. However, the noticeable enhancement effect of Twitter data on other control data, especially for age groups with a high percentage of Twitter users, suggests that it helps to better reflect population distribution by increasing variation in densities within a residential area delineated by other control data.},
  author          = {Lin, Jie and Cromley, Robert G.},
  doi             = {10.1016/j.apgeog.2015.01.006},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Lin, Cromley - 2015 - Evaluating geo-located Twitter data as a control layer for areal interpolation of population.pdf:pdf},
  isbn            = {01436228},
  issn            = {01436228},
  journal         = {Applied Geography},
  keywords        = {Areal interpolation,Geo-located Twitter,Remotely sensed imagery,Volunteered geographic information},
  mendeley-groups = {boundary-harmonization},
  pages           = {41--47},
  publisher       = {Elsevier Ltd},
  title           = {{Evaluating geo-located Twitter data as a control layer for areal interpolation of population}},
  url             = {http://dx.doi.org/10.1016/j.apgeog.2015.01.006},
  volume          = {58},
  year            = {2015}
}
@article{Lin2015a,
  abstract        = {Areal interpolation is a technique used to transfer attribute information from source zones with known values to target zones with unknown values. This paper presents and describes a new polycategorical method that integrates positive aspects of both geographically weighted regression (GWR)-based and quantile regression (QR)-based interpolators for solving areal interpolation problems. Two different types of neighborhoods for selecting observations used to estimate ancillary control densities are presented: one that is spatially based and one that is statistically based. The new polycategorical methods are evaluated against a number of existing methods - areal weighting, pycnophylactic, binary dasymetric, intelligent dasymetric mapping, and GWR using test data from the 2010 census population, the National Land Cover Database 2006 (NLCD2006) and the Topologically Integrated Geographic Encoding and Reference (TIGER) line graph files. The evaluations include several overall error measurement indices as well as maps of the spatial distribution of the error associated with selected methods. Results suggest that with appropriate land cover categories and neighborhoods, the new polycategorical methods provide comparable results to local regression models but with much less computation complexity.},
  author          = {Lin, Jie and Cromley, Robert G.},
  doi             = {10.1016/j.compenvurbsys.2015.05.007},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Lin, Cromley - 2015 - A local polycategorical approach to areal interpolation.pdf:pdf},
  issn            = {01989715},
  journal         = {Computers, Environment and Urban Systems},
  keywords        = {Areal interpolation,Geographically weighted regression,Local statistical,Quantile regression,urban-modeling},
  mendeley-groups = {boundary-harmonization,urban-modeling},
  mendeley-tags   = {urban-modeling},
  pages           = {23--31},
  publisher       = {Elsevier Ltd},
  title           = {{A local polycategorical approach to areal interpolation}},
  url             = {http://dx.doi.org/10.1016/j.compenvurbsys.2015.05.007},
  volume          = {54},
  year            = {2015}
}
@article{Logan_2014,
  author          = {Logan, John R and Xu, Zengwang and Stults, Brian J.},
  doi             = {10.1080/00330124.2014.905156},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Logan, Xu, Stults - 2014 - Interpolating U.S. Decennial Census Tract Data from as Early as 1970 to 2010 A Longitudinal Tract Database.pdf:pdf},
  issn            = {1467-9272},
  journal         = {The Professional Geographer},
  keywords        = {2010 census,a common situation faced,areal interpolation,by researchers using areal,census geography,census tract,data is discrepancies in,population interpolation,the boundaries},
  mendeley-groups = {datasets,segregation,boundary-harmonization},
  month           = {may},
  number          = {3},
  pages           = {412--420},
  publisher       = {Informa UK Limited},
  title           = {{Interpolating U.S. Decennial Census Tract Data from as Early as 1970 to 2010: A Longitudinal Tract Database}},
  url             = {http://www.tandfonline.com/doi/abs/10.1080/00330124.2014.905156 http://dx.doi.org/10.1080/00330124.2014.905156},
  volume          = {66},
  year            = {2014}
}
@article{Maantay2007,
  abstract        = {This paper discusses the importance of determining an accurate depiction of total population and specific sub-population distribution for urban areas in order to develop an improved "denominator," which would enable the calculation of more correct rates in GIS analyses involving public health, crime, and urban environmental planning. Rather than using data aggregated by arbitrary administrative boundaries such as census tracts, we use dasymetric mapping, an areal interpolation method using ancillary information to delineate areas of homogeneous values. We review previous dasymetric mapping techniques (which often use remotely sensed land-cover data) and contrast them with our technique, Cadastral-based Expert Dasymetric System (CEDS), which is particularly suitable for urban areas. The CEDS method uses specific cadastral data, land-use filters, modeling by expert system routines, and validation against various census enumeration units and other data. The CEDS dasymetric mapping technique is presented through a case study of asthma hospitalizations in the Bronx, New York City, in relation to proximity buffers constructed around major sources of air pollution. The case study shows the impact that a more accurate estimation of population distribution has on a current environmental justice and health disparities research project, and the potential of CEDS for other GIS applications.},
  author          = {Maantay, Juliana Astrud and Maroko, Andrew R. and Herrmann, Christopher},
  doi             = {10.1559/152304007781002190},
  file            = {:Users/knaaptime/Dropbox/Academic/literature/Mapping Population Distribution in the Urban Environment The Cadastral based Expert Dasymetric System CEDS.pdf:pdf},
  issn            = {1523-0406},
  journal         = {Cartography and Geographic Information Science},
  keywords        = {Areal interpolation,Areal weighting,Asthma,Cadastral maps,Dasymetric,Expert systems,Geographic information systems,New York City,Thematic maps},
  mendeley-groups = {boundary-harmonization},
  month           = {jan},
  number          = {2},
  pages           = {77--102},
  title           = {{Mapping Population Distribution in the Urban Environment: The Cadastral-based Expert Dasymetric System (CEDS)}},
  url             = {http://www.tandfonline.com/doi/abs/10.1559/152304007781002190},
  volume          = {34},
  year            = {2007}
}
@article{Nagle2014,
  abstract        = {Dasymetric models increase the spatial resolution of population data by incorporating related ancillary data layers. The role of uncertainty in dasymetric modeling has not been fully addressed as of yet. Uncertainty is usually present because most population data are themselves uncertain, or the geographic processes that connect population and the ancillary data layers are not precisely known. A new dasymetric methodology-the penalized maximum entropy dasymetric model (P-MEDM)-is presented that enables these sources of uncertainty to be represented and modeled. The P-MEDM propagates uncertainty through the model and yields fine-resolution population estimates with associated measures of uncertainty. This methodology contains a number of other benefits of theoretical and practical interest. In dasymetric modeling, researchers often struggle with identifying a relationship between population and ancillary data layers. The P-MEDM model simplifies this step by unifying how ancillary data are included. The P-MEDM also allows a rich array of data to be included, with disparate spatial resolutions, attribute resolutions, and uncertainties. Although the P-MEDM does not necessarily produce more precise estimates than do existing approaches, it does help to unify how data enter the dasymetric model, it increases the types of data that can be used, and it allows geographers to characterize the quality of their dasymetric estimates. We present an application of the P-MEDM that includes household-level survey data combined with higher spatial resolution data such as from census tracts, block groups, and land cover classifications. {\textcopyright} 2014 Copyright Taylor and Francis Group, LLC.},
  author          = {Nagle, Nicholas N. and Buttenfield, Barbara P. and Leyk, Stefan and Spielman, Seth},
  doi             = {10.1080/00045608.2013.843439},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Nagle et al. - 2014 - Dasymetric Modeling and Uncertainty.pdf:pdf},
  issn            = {0004-5608},
  journal         = {Annals of the Association of American Geographers},
  keywords        = {dasymetric modeling,maximum entropy,small area estimation},
  mendeley-groups = {boundary-harmonization},
  month           = {jan},
  number          = {1},
  pages           = {80--95},
  publisher       = {Informa UK Limited},
  title           = {{Dasymetric Modeling and Uncertainty}},
  url             = {http://dx.doi.org/10.1080/00045608.2013.843439 https://www.tandfonline.com/doi/full/10.1080/00045608.2013.843439},
  volume          = {104},
  year            = {2014}
}
@article{Noble2013,
  archiveprefix   = {arXiv},
  arxivid         = {NIHMS150003},
  author          = {Noble, Petra and {Van Riper}, David and Ruggles, Steven and Schroeder, Jonathan and Hindman, Monty},
  doi             = {10.1080/01615440.2011.563228},
  eprint          = {NIHMS150003},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Noble et al. - 2011 - Harmonizing Disparate Data across Time and Place The Integrated Spatio-Temporal Aggregate Data Series.pdf:pdf},
  isbn            = {3149778794},
  issn            = {0161-5440},
  journal         = {Historical Methods: A Journal of Quantitative and Interdisciplinary History},
  keywords        = {aggregate data,census data,data integration,data series,disseminate integrated statistical and,geographic data for the,gis,istads,the integrated spatio-temporal aggregate,united states covering the,will create and freely},
  mendeley-groups = {boundary-harmonization},
  month           = {apr},
  number          = {2},
  pages           = {79--85},
  pmid            = {1000000221},
  title           = {{Harmonizing Disparate Data across Time and Place: The Integrated Spatio-Temporal Aggregate Data Series}},
  url             = {http://www.tandfonline.com/doi/abs/10.1080/01615440.2011.563228},
  volume          = {44},
  year            = {2011}
}
@article{Openshaw1984,
  abstract        = {The author examines problems related to the fact that in many countries, census data are only reported for areal units and not at the individual level. Attention is paid to the question of ecological fallacy problems that arise from this situation. Data from a 10 percent sample of the United Kingdom population and individual census data from Italy are used to illustrate the problem. "It is concluded that ecological fallacy effects are endemic to areal census data, although their magnitude is perhaps not as large as might have been expected. The principal difficulty is that there is at present no way of predicting in advance the degree of severity likely to be associated with particular variables and particular techniques. Finally, a suggestion is made concerning how the potentially serious practical consequences can be reduced."},
  author          = {Openshaw, S},
  doi             = {10.1068/a160017},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Openshaw - 1984 - Ecological Fallacies and the Analysis of Areal Census Data.pdf:pdf},
  isbn            = {1111111111},
  issn            = {0308-518X},
  journal         = {Environment and Planning A: Economy and Space},
  mendeley-groups = {boundary-harmonization},
  month           = {jan},
  number          = {1},
  pages           = {17--31},
  pmid            = {12265900},
  title           = {{Ecological Fallacies and the Analysis of Areal Census Data}},
  url             = {http://journals.sagepub.com/doi/10.1068/a160017},
  volume          = {16},
  year            = {1984}
}
@article{Qiu2013,
  abstract        = {Frequently in spatial analysis, data are collected using one measurement system while analyses are conducted using a different measurement system. In these two systems, data regarding individual objects often are aggregated into areal units because (1) data concerning personal information are restricted by privacy and confidentiality regulations; (2) aggregated data require less storage and have a computational advantage over data in disaggregated form; and (3) geographers traditionally study data at a regional level (Openshaw and Taylor 1981). Areal interpolation refers to the procedures for transferring attribute data from one partitioning of geographic space (a set of source units) to another (a set of target units) (Goodchild and Lam 1980). Areal interpolation is needed to estimate attribute information for different geographic partitionings at the same scale (an alternative geography problem), for spatial partitionings at a finer resolution (a small area problem), for reconciling boundary changes in spatial units over time (a temporal mismatch problem), or for incomplete coverage (a missing data problem). Geographic information systems (GISs) have increased the need to change measurement systems because a GIS integrates source data from different systems into a common database, and GIS analyses also create new data layers with different spatial units from source layers, such as in an overlay operation. As areal interpolation methods for solving these aforementioned estimation problems devel-oped, several critical components to the solution methodology emerged. First, different statistical methods were adapted for areal interpolation, ranging from simple proportions to more sophis-ticated procedures such as expectation maximization (EM) algorithms and various forms of regression analysis. Second, many of these methods began to incorporate ancillary data that act as control units on the geographic distribution of the attributes being estimated. In doing so, source data are used to estimate a density surface for control units, such as in dasymetric mapping, followed by this density surface being aggregated by target zones to create final estimates. Consequently, researchers have focused not only on better analytical methods but also on the incorporation of better data that are available for source zones and control zones. The purpose of this special issue is to examine the status of these developments in areal interpolation. The first three articles involve expanding, improving, and redeveloping a popular areal interpolation approach, the EM algorithm. Schroeder and Van Riper (2013) present a geographically weighted expectation-maximization (GWEM) dasymetric interpolation algo-rithm. Their approach expands existing EM algorithms by introducing the benefits of geographi-cally weighted regression (GWR), which allows the densities of different control units to have a different ratio among all source units. The GWEM algorithm incorporates the best of both EM and GWR, while overcoming the limitations of each individual technique. Schroeder and Van Riper use their GWEM algorithm to interpolate historical 1980 census data backward to 1970 data with land use and land cover data as control units. It achieves better accuracy than that 213 reported in earlier studies. Additional improvements are made by incorporating target-density weight as extra ancillary information. Sridharan and Qiu (2013) present a spatially disaggregated EM algorithm using light detec-tion and ranging (LiDAR)-derived residential building volume as the control variable. Their model specification improves upon pixel-based approaches using a least squares approximation to the EM algorithm in which areal interpolation is treated as missing data. LiDAR-derived building volume accounts for the vertical distribution of population, which one-dimensional length data such as roadways and two-dimensional area data are unable to measure. These authors propose new approaches for the initialization of, iterative adjustment in, and stopping criterion for their EM model that are more appropriate for varying-sized control units, replacing the equal-sized pixel control units used in earlier EM applications. A case study compares the performance of various designs and then evaluates these designs against earlier areal interpola-tion models in terms of accuracy and precision. Griffith (2013) applies the EM method to the problem of missing data. His research builds on his earlier work using the EM method to impute missing values. Here, the problem is to apply the EM algorithm to a georeferenced Poisson random variable of counts. A mixed model is implemented and contrasted with a Poisson-gamma mixture (i.e., negative binomial) model. Several experiments show that temporal covariates decay in usefulness over time and that temporal covariates (a 10-year lag) produce better results than a purely spatial contemporaneous covariate of the structure of reported values. He also explores the use of regional total constraints and of spatially structured random effects. The next three articles explore nontraditional data for source, target, and control units, with improved algorithms specifically designed to work with these data. Leyk, Nagle, and Buttenfield (2013) summarize research that is different from most other areal interpolation applications in this special issue, where values at area source units often are spatially disaggregated into smaller units, such as households (Bentley, Cromley, and Atkinson-Palombo 2013; Sridharan and Qiu 2013), before reaggregating into target units. The source data in their application are household records from public use microdata sample (PUMS) files, which contain rich attribute information. The uniqueness of these source data lies in not only that they constitute a small 5{\%} sample but also that their spatial location is unknown. A maximum entropy model spatially allocates records from the PUMS files to census tracts based on a set of related variables and a limiting variable (i.e., a control unit) in the form of land cover data. The sampling weights imputed using the maximum entropy model also provide household-level uncertainty for the dasymetric modeling process. Bentley, Cromley, and Atkinson-Palombo (2013) extend a network interpolation method proposed by Maantay, Maroko, and Herrmann (2007) by coupling areal control units in the form of cadastral lots with the already-used linear control units of street segments. They implement their extension of the method by incorporating Tobler's (1979) pycnophylactic method to smooth interpolated values so that the population density on one side of a street segment is similar to that on the other side of that segment, while maintaining the pycnophylactic property. The extended method is successfully applied to a flow modeling problem. The distinctiveness of their appli-cation is that the target units are dynamically defined service areas during the flow modeling process. Their new network interpolation methods exhibit better performance than an area-based interpolation approach to flow modeling. Finally, Langford (2013) explores the accuracy of areal interpolation in providing small area population estimates, where " small areas " are defined as target zones much smaller than those of Geographical Analysis},
  author          = {Qiu, Fang and Cromley, Robert},
  doi             = {10.1111/gean.12016},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Qiu, Cromley - 2013 - Areal Interpolation and Dasymetric Modeling.pdf:pdf},
  isbn            = {1538-4632},
  issn            = {00167363},
  journal         = {Geographical Analysis},
  mendeley-groups = {boundary-harmonization},
  month           = {jul},
  number          = {3},
  pages           = {213--215},
  title           = {{Areal Interpolation and Dasymetric Modeling}},
  url             = {http://doi.wiley.com/10.1111/gean.12016},
  volume          = {45},
  year            = {2013}
}
@article{Reibel2007,
  abstract        = {The need to combine spatial data representing sociodemographic information across incompatible spatial units is a common problem for demographers. A particular concern is computing small area trends when aggregation zone boundaries change during the trend interval. To that end, this study provides an example of dasymetric areal interpolation using the pre-classified land cover data available through the US Geological Survey's National Land Cover Dataset (NLCD) program. Areal interpolation of population estimates is preferable to traditional reaggregation techniques, and the use of land cover data as a weighting factor in interpolated estimation has been shown in earlier studies to be highly accurate. In this study, the NLCD data set performs well and, because it requires no classification, it compares favorably with other land cover data sets for areal interpolation when considered on the basis of accuracy, precision and ease of use.},
  author          = {Reibel, Michael and Agrawal, Aditya},
  doi             = {10.1007/s11113-007-9050-9},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Reibel, Agrawal - 2007 - Areal Interpolation of Population Counts Using Pre-classified Land Cover Data.pdf:pdf},
  issn            = {0167-5923},
  journal         = {Population Research and Policy Review},
  keywords        = {Areal interpolation,Census geography,GIS,Population estimates},
  mendeley-groups = {spatial-analysis,methods,segregation,boundary-harmonization,neighborhoods},
  month           = {nov},
  number          = {5-6},
  pages           = {619--633},
  publisher       = {Springer Nature},
  title           = {{Areal Interpolation of Population Counts Using Pre-classified Land Cover Data}},
  url             = {http://dx.doi.org/10.1007/s11113-007-9050-9 http://link.springer.com/10.1007/s11113-007-9050-9},
  volume          = {26},
  year            = {2007}
}
@article{Reibel_2005,
  author          = {Reibel, Michael and Bufalino, Michael E},
  doi             = {10.1068/a36202},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Reibel, Bufalino - 2005 - Street-Weighted Interpolation Techniques for Demographic Count Estimation in Incompatible Zone Systems.pdf:pdf},
  issn            = {0308-518X},
  journal         = {Environment and Planning A: Economy and Space},
  mendeley-groups = {segregation,boundary-harmonization},
  month           = {jan},
  number          = {1},
  pages           = {127--139},
  publisher       = {SAGE Publications},
  title           = {{Street-Weighted Interpolation Techniques for Demographic Count Estimation in Incompatible Zone Systems}},
  url             = {http://dx.doi.org/10.1068/a36202 http://journals.sagepub.com/doi/10.1068/a36202},
  volume          = {37},
  year            = {2005}
}
@article{Sadahiro1999,
  abstract        = {This paper discusses the accuracy of spatial data estimated by areal interpolation, a processs of transfering data from one zonal system to anther. A stochastic model is proposed wchich represents areal interpolations in diverse geographic situations. The model is used to examine the relationship netween estimation accuracy of areal interpolation. Four areal interpolation methods are then assessed through numerical examinations. From this it is found that the accuracy of simple interpolation methodf heavily depends on yhe appropriateness of their hypothetical distributions, whereas the accuracy of intelligent methods depends on the fitness of the range of suplementary data for that of true distribution.},
  author          = {Sadahiro, Yukio},
  doi             = {10.1007/s101090050017},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Sadahiro - 1999 - Accuracy of areal interpolation A comparison of alternative methods.pdf:pdf},
  isbn            = {1435-5930},
  issn            = {1435-5930},
  journal         = {Journal of Geographical Systems},
  keywords        = {accuracy,areal interpolation,c10,c15,c81,cation,error distribution,jel classi,stochastic model},
  mendeley-groups = {boundary-harmonization},
  number          = {4},
  pages           = {323--346},
  title           = {{Accuracy of areal interpolation: A comparison of alternative methods}},
  url             = {http://link.springer.com/10.1007/s101090050017},
  volume          = {1},
  year            = {1999}
}
@article{Schroeder2017,
  abstract        = {To measure population changes in areas where census unit boundaries do not align across time, a common approach is to interpolate data from one census's units to another's. This article presents a broad assessment of areal interpolation models for estimating counts of 2000 characteristics in 2010 census units throughout the United States. We interpolate from 2000 census block data using 4 types of ancillary data to guide interpolation: 2010 block densities, imperviousness data, road buffers, and water body polygons. We test 8 binary dasymetric (BD) models and 8 target-density weighting (TDW) models, each using a unique combination of the 4 ancillary data types, and derive 2 hybrid models that blend the best-performing BD and TDW models. The most accurate model is a hybrid that generally gives high weight to TDW (allocating 2000 data in proportion to 2010 densities) but gives increasing weight to a BD model (allocating data uniformly within developed land near roads) in proportion to the estimated 2000â€“2010 rate of change within each block. Although for most 2010 census units, this hybrid model's estimates differ little from the simplest model's estimates, there are still many areas where the estimates differ considerably. Estimates from the final model, along with lower and upper bounds for each estimate, are publicly available for over 1000 population and housing characteristics at 10 geographic levels via the National Historical Geographic Information System (NHGIS â€“ http://nhgis.org).},
  author          = {Schroeder, Jonathan P.},
  doi             = {10.1016/j.compenvurbsys.2016.10.001},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Schroeder - 2017 - Hybrid areal interpolation of census counts from 2000 blocks to 2010 geographies.pdf:pdf},
  isbn            = {01989715 (ISSN)},
  issn            = {01989715},
  journal         = {Computers, Environment and Urban Systems},
  keywords        = {Areal interpolation,Census geography,Population estimation,Spatio-temporal analysis,urban-modeling},
  mendeley-groups = {boundary-harmonization,urban-modeling},
  mendeley-tags   = {urban-modeling},
  month           = {mar},
  pages           = {53--63},
  publisher       = {Elsevier Ltd},
  title           = {{Hybrid areal interpolation of census counts from 2000 blocks to 2010 geographies}},
  url             = {http://dx.doi.org/10.1016/j.compenvurbsys.2016.10.001},
  volume          = {62},
  year            = {2017}
}
@article{Schroeder_2007,
  author          = {Schroeder, Jonathan P},
  doi             = {10.1111/j.1538-4632.2007.00706.x},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Schroeder - 2007 - Target-Density Weighting Interpolation and Uncertainty Evaluation for Temporal Analysis of Census Data.pdf:pdf},
  issn            = {1538-4632},
  journal         = {Geographical Analysis},
  mendeley-groups = {segregation,boundary-harmonization},
  month           = {jul},
  number          = {3},
  pages           = {311--335},
  publisher       = {Wiley-Blackwell},
  title           = {{Target-Density Weighting Interpolation and Uncertainty Evaluation for Temporal Analysis of Census Data}},
  url             = {http://dx.doi.org/10.1111/j.1538-4632.2007.00706.x},
  volume          = {39},
  year            = {2007}
}
@article{Schroeder_2013,
  abstract        = {Areal interpolation transforms data for a variable of interest from a set of source zones to estimate the same variable's distribution over a set of target zones. One common practice has been to guide interpolation by using ancillary control zones that are related to the variable of interest's spatial distribution. This guidance typically involves using source zone data to estimate the density of the variable of interest within each control zone. This article introduces a novel approach to density estimation, the geographically weighted expectation-maximization (GWEM) algorithm, which combines features of two previously used techniques, the expectation-maximization (EM) algorithm and geographically weighted regression. The EM algorithm provides a framework for incorporating proper constraints on data distributions, and using geographical weighting allows estimated control-zone density ratios to vary spatially. We assess the accuracy of GWEM by applying it with land-use/land-cover ancillary data to population counts from a nationwide sample of 1980 United States census tract pairs. We find that GWEM generally is more accurate in this setting than several previously studied methods. Because target-density weighting (TDW)-using 1970 tract densities to guide interpolation-outperforms GWEM in many cases, we also consider two GWEM-TDW hybrid approaches, and find them to improve estimates substantially.},
  author          = {Schroeder, Jonathan P and {Van Riper}, David C},
  doi             = {10.1111/gean.12014},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Schroeder, Van Riper - 2013 - Because Muncie's Densities Are Not Manhattan's Using Geographical Weighting in the Expectation-Maximizatio.pdf:pdf},
  issn            = {00167363},
  journal         = {Geographical Analysis},
  mendeley-groups = {segregation,boundary-harmonization},
  month           = {jul},
  number          = {3},
  pages           = {216--237},
  publisher       = {Wiley-Blackwell},
  title           = {{Because Muncie's Densities Are Not Manhattan's: Using Geographical Weighting in the Expectation-Maximization Algorithm for Areal Interpolation}},
  url             = {http://dx.doi.org/10.1111/gean.12014 http://doi.wiley.com/10.1111/gean.12014},
  volume          = {45},
  year            = {2013}
}


@article{Sridharan2013,
  abstract        = {Dasymetric areal interpolation is the process by which data are transferred from a spatial unit system for which they are available (source units) to another system for which they are required (target units) with the aid of ancillary information (control units). We propose a spatially disaggregated areal interpolation model for population data using light detection and ranging (LiDAR)-derived building volumes as an ancillary variable. Innovative methods are proposed for model initialization, iterative regression and adjustment, and stopping criteria to deal effectively with control units of unequal size. The model is derived and applied at the control unit level to minimize the modifiable areal unit problem, and an iterative adjustment process is utilized to overcome the spatial heterogeneity problem encountered in earlier approaches. The use of building volume to disaggregate the popu- lation into finer scales ensures maximum correspondence with the unit at which the original population data were collected and models not only the horizontal but also the vertical population distribution. A case study for Round Rock, Texas, demonstrates that the pro- posed spatially disaggregated model using LiDAR-derived building volumes outperforms earlier areal interpolation models using traditional area- and length-based ancillary variables.},
  author          = {Sridharan, Harini and Qiu, Fang},
  doi             = {10.1111/gean.12010},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Sridharan, Qiu - 2013 - A Spatially Disaggregated Areal Interpolation Model Using Light Detection and Ranging-Derived Building Volumes.pdf:pdf},
  isbn            = {1538-4632},
  issn            = {00167363},
  journal         = {Geographical Analysis},
  mendeley-groups = {boundary-harmonization},
  month           = {jul},
  number          = {3},
  pages           = {238--258},
  title           = {{A Spatially Disaggregated Areal Interpolation Model Using Light Detection and Ranging-Derived Building Volumes}},
  url             = {http://doi.wiley.com/10.1111/gean.12010},
  volume          = {45},
  year            = {2013}
}
@article{Tsutsumi2014,
  abstract        = {{\textcopyright} 2012 SAGE Publications. Spatial data are often aggregated into spatial units and differences between spatial units can complicate the analysis of the data. One solution to this problem is spatial unit conversion, also called areal interpolation. Of the many areal interpolation methods proposed thus far, few method are based on spatial econometrics: a subset of econometrics which is concerned with the role of spatial autocorrelation (a general property of spatial data that implies that data in nearby locations are similar) in the regional economic model response. In this article, an areal interpolation method that considers both the spatial autocorrelation and the pycnophylactic property (a most basic premise of areal interpolation that the sum of the data given in a specific area must be constant) is proposed by combining a spatial econometric model and a linear regression-based areal interpolation method. Parameters of the proposed method are estimated using the expectation-maximization algorithm. The performance of the proposed method was examined through empirical analysis using real data and ratios on aging populations. The results indicate the importance of considering both the pycnophylactic property and the spatial autocorrelation in areal interpolation. The results also show the applicability of spatial econometrics to areal interpolation problems.},
  author          = {Tsutsumi, Morito and Murakami, Daisuke},
  doi             = {10.1177/0160017612463233},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Tsutsumi, Murakami - 2014 - New Spatial Econometricsâ€“Based Areal Interpolation Method.pdf:pdf},
  issn            = {0160-0176},
  journal         = {International Regional Science Review},
  keywords        = {{\&} Murakami,273â€“297. https://doi.org/10.1177/0160017612463233a,37(3),D. (2014). New Spatial Econometricsâ€“Based Areal In,M.,general theory,general theory and history,geographic information science,human spatial structure,methods,population and employment distribution,spatial Tsutsumi,spatial statistics and spatial econometrics,spatial structure,urban and regional spatial structure},
  mendeley-groups = {spatial-analysis,boundary-harmonization},
  month           = {jul},
  number          = {3},
  pages           = {273--297},
  title           = {{New Spatial Econometricsâ€“Based Areal Interpolation Method}},
  url             = {http://journals.sagepub.com/doi/10.1177/0160017612463233},
  volume          = {37},
  year            = {2014}
}
@article{mennis06_intel_dasym_mappin_its_applic,
  abstract        = {This research presents a new "intelligent" dasymetric mapping technique (IDM), which combines an analyst's domain knowledge with a data-driven methodology to specify the functional relationship of the ancillary classes with the underlying statistical surface being mapped. The data-driven component of IDM employs a flexible empirical sampling approach to acquire information on the data densities of individual ancillary classes, and it uses the ratio of class densities to redistribute population to sub-source zone areas. A summary statistics table characterizing the resulting dasymetric map can be used to compare the quality of the output of different IDM parameterizations. A case study of four population variables is used to demonstrate IDM and provide a visual and quantitative error assessment comparing various IDM parameterizations with areal weighting and conventional "binary" dasymetric mapping. Intelligent dasymetric mapping outperforms areal weighting, and certain IDM parameterizations outperform binary dasymetric mapping.},
  archiveprefix   = {arXiv},
  arxivid         = {arXiv:1011.1669v3},
  author          = {Mennis, Jeremy and Hultgren, Torrin},
  doi             = {10.1559/152304006779077309},
  eprint          = {arXiv:1011.1669v3},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Mennis, Hultgren - 2006 - Intelligent Dasymetric Mapping and Its Application to Areal Interpolation.pdf:pdf},
  isbn            = {1523040067790},
  issn            = {1523-0406},
  journal         = {Cartography and Geographic Information Science},
  mendeley-groups = {boundary-harmonization},
  number          = {3},
  pages           = {179--194},
  pmid            = {20621331},
  title           = {{Intelligent Dasymetric Mapping and Its Application to Areal Interpolation}},
  url             = {http://www.tandfonline.com/doi/abs/10.1559/152304006779077309 https://doi.org/10.1559/152304006779077309},
  volume          = {33},
  year            = {2006}
}
@article{tobler_smooth_1979,
  abstract        = {Census enumerations are usually packaged in irregularly shaped geographical regions. Interior values can be interpolated for such regions, without specification of "control points," by using an analogy to elliptical partial differential equations. A solution procedure is suggested, using finite difference methods with classical boundary conditions. In order to estimate densities, an additional nonnegativity condition is required. Smooth contour maps, which satisfy the volume preserving and nonnegativity constraints, illustrate the method using actual geographical data. It is suggested that the procedure may be used to convert observations from one bureaucratic partitioning of a geographical area to another.},
  author          = {Tobler, Waldo R},
  doi             = {10.1080/01621459.1979.10481647},
  file            = {:Users/knaaptime/Library/Application Support/Mendeley Desktop/Downloaded/Tobler - 1979 - Smooth Pycnophylactic Interpolation for Geographical Regions.pdf:pdf},
  isbn            = {978-0-511-47935-9},
  issn            = {0162-1459},
  journal         = {Journal of the American Statistical Association},
  keywords        = {bivariate interpolation,density estimation,dirichlet integral,interpolation,methods,numerical,population density},
  mendeley-groups = {boundary-harmonization},
  month           = {sep},
  number          = {367},
  pages           = {519--529},
  title           = {{Smooth pycnophylactic interpolation for geographical regions}},
  url             = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1979.10481647},
  volume          = {74},
  year            = {1979}
}
